{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    !git clone  https://github.com/ecastillot/delaware.git ./delaware\n",
    "    !pip install obspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "version = \"10102024\"\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    dw_path = os.path.join(\"/content/delaware\",version)\n",
    "else:\n",
    "    dw_path = os.path.join(\"/home/emmanuel/ecastillo/dev/delaware\",version)\n",
    "    \n",
    "sys.path.append(dw_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from delaware.core.read import EQPicks\n",
    "from delaware.core.eqviewer import Stations\n",
    "from delaware.loc.inv import prepare_cat2vps\n",
    "import pandas as pd\n",
    "import os\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from typing import Tuple, List, Dict\n",
    "from scipy.stats import mode\n",
    "\n",
    "def load_stations(stations_path: str, proj: str) -> object:\n",
    "    \"\"\"\n",
    "    Load station data and return a Stations object.\n",
    "\n",
    "    Args:\n",
    "        stations_path (str): Path to the stations CSV file.\n",
    "        proj (str): EPSG projection for the station data.\n",
    "\n",
    "    Returns:\n",
    "        Stations: An object containing station data.\n",
    "    \"\"\"\n",
    "    stations = pd.read_csv(stations_path)\n",
    "    stations_columns = [\"network\", \"station\", \"latitude\", \"longitude\", \"elevation\"]\n",
    "    stations = stations[stations_columns]\n",
    "    stations[\"station_index\"] = stations.index\n",
    "    stations_obj = Stations(data=stations, xy_epsg=proj)\n",
    "    return stations_obj\n",
    "\n",
    "def get_single_station(stations: object, station_name: str) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Extract information for a single station by name.\n",
    "\n",
    "    Args:\n",
    "        stations (object): Stations object containing station data.\n",
    "        station_name (str): Name of the station to extract.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: Data for the specified station.\n",
    "    \"\"\"\n",
    "    single_station = stations.data[stations.data[\"station\"] == station_name].iloc[0]\n",
    "    return single_station\n",
    "\n",
    "def load_eqpicks(root: str, author: str, proj: str, catalog_path: str, picks_path: str,\n",
    "                 catalog_header_line=1) -> object:\n",
    "    \"\"\"\n",
    "    Load earthquake picks and return an EQPicks object.\n",
    "\n",
    "    Args:\n",
    "        root (str): Root directory for the data.\n",
    "        author (str): Author name for the picks.\n",
    "        proj (str): EPSG projection for the picks.\n",
    "        catalog_path (str): Path to the catalog CSV file.\n",
    "        picks_path (str): Path to the picks database file.\n",
    "\n",
    "    Returns:\n",
    "        EQPicks: An object containing earthquake picks data.\n",
    "    \"\"\"\n",
    "    return EQPicks(root, author=author, xy_epsg=proj, \n",
    "                   catalog_header_line=catalog_header_line,\n",
    "                   catalog_path=catalog_path, picks_path=picks_path)\n",
    "\n",
    "def process_catalog_and_picks(eq_picks: object, single_station: pd.Series,\n",
    "                              stations: Stations,r) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Process catalog and picks for a single station.\n",
    "\n",
    "    Args:\n",
    "        eq_picks (object): EQPicks object containing picks and catalog data.\n",
    "        single_station (pd.Series): Data for a single station.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[pd.DataFrame, pd.DataFrame]: Processed catalog and picks data.\n",
    "    \"\"\"\n",
    "    src = (single_station.latitude, single_station.longitude, r, None)\n",
    "    catalog, picks = eq_picks.get_catalog_with_picks(region_from_src=src)\n",
    "    catalog, picks = prepare_cat2vps(catalog.data, picks.data, stations.data)\n",
    "    picks = picks[picks[\"station\"] == single_station.station]\n",
    "    catalog = catalog[catalog['ev_id'].isin(picks['ev_id'])]\n",
    "    return catalog, picks\n",
    "\n",
    "def preprocess_picks(picks: pd.DataFrame, catalog: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Preprocess picks data by merging with catalog and calculating arrival times.\n",
    "\n",
    "    Args:\n",
    "        picks (pd.DataFrame): Picks data.\n",
    "        catalog (pd.DataFrame): Catalog data.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Preprocessed picks data.\n",
    "    \"\"\"\n",
    "    picks_data = pd.merge(picks, catalog, on=[\"ev_id\"])\n",
    "    picks_data['arrival_time_P'] = pd.to_datetime(picks_data['arrival_time_P']) - pd.to_datetime(picks_data['origin_time'])\n",
    "    picks_data['arrival_time_S'] = pd.to_datetime(picks_data['arrival_time_S']) - pd.to_datetime(picks_data['origin_time'])\n",
    "    picks_data['arrival_time_P'] = picks_data['arrival_time_P'].apply(lambda x: x.total_seconds())\n",
    "    picks_data['arrival_time_S'] = picks_data['arrival_time_S'].apply(lambda x: x.total_seconds())\n",
    "    return picks_data\n",
    "\n",
    "def calculate_vij(picks_data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate v_ij for all combinations of picks.\n",
    "\n",
    "    Args:\n",
    "        picks_data (pd.DataFrame): Preprocessed picks data.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing v_ij results.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    good_logs, bad_logs = [], []\n",
    "\n",
    "    for i, j in combinations(picks_data.index, 2):\n",
    "        delta_t_S = picks_data.loc[i, 'arrival_time_S'] - picks_data.loc[j, 'arrival_time_S']\n",
    "        delta_t_P = picks_data.loc[i, 'arrival_time_P'] - picks_data.loc[j, 'arrival_time_P']\n",
    "        v_ij = delta_t_S / delta_t_P if delta_t_P != 0 else None\n",
    "\n",
    "        log = {\n",
    "            \"ev_i\": picks_data.loc[i, 'ev_id'],\n",
    "            \"ev_j\": picks_data.loc[j, 'ev_id'],\n",
    "            \"station\": picks_data.loc[i, 'station'],\n",
    "            \"v_ij\": v_ij\n",
    "        }\n",
    "\n",
    "        if v_ij is not None and v_ij > 0:\n",
    "            results.append(log)\n",
    "            good_logs.append(log)\n",
    "        else:\n",
    "            bad_logs.append(log)\n",
    "\n",
    "    print(f\"Good: {len(good_logs)}, Bad: {len(bad_logs)}\")\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PB35\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Missing column provided to 'parse_dates': 'origin_time'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/emmanuel/ecastillo/dev/delaware/02032024/project/vpvs/vps_stations.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/emmanuel/ecastillo/dev/delaware/02032024/project/vpvs/vps_stations.ipynb#W3sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m single_station \u001b[39m=\u001b[39m get_single_station(stations, station_name)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/emmanuel/ecastillo/dev/delaware/02032024/project/vpvs/vps_stations.ipynb#W3sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Load EQPicks\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/emmanuel/ecastillo/dev/delaware/02032024/project/vpvs/vps_stations.ipynb#W3sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m eq_picks \u001b[39m=\u001b[39m load_eqpicks(root, author, proj, catalog_path, picks_path)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/emmanuel/ecastillo/dev/delaware/02032024/project/vpvs/vps_stations.ipynb#W3sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m# Process catalog and picks\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/emmanuel/ecastillo/dev/delaware/02032024/project/vpvs/vps_stations.ipynb#W3sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m catalog, picks \u001b[39m=\u001b[39m process_catalog_and_picks(eq_picks, single_station,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/emmanuel/ecastillo/dev/delaware/02032024/project/vpvs/vps_stations.ipynb#W3sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m                                            stations\u001b[39m=\u001b[39mstations,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/emmanuel/ecastillo/dev/delaware/02032024/project/vpvs/vps_stations.ipynb#W3sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m                                            r\u001b[39m=\u001b[39mr)\n",
      "\u001b[1;32m/home/emmanuel/ecastillo/dev/delaware/02032024/project/vpvs/vps_stations.ipynb Cell 4\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/emmanuel/ecastillo/dev/delaware/02032024/project/vpvs/vps_stations.ipynb#W3sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_eqpicks\u001b[39m(root: \u001b[39mstr\u001b[39m, author: \u001b[39mstr\u001b[39m, proj: \u001b[39mstr\u001b[39m, catalog_path: \u001b[39mstr\u001b[39m, picks_path: \u001b[39mstr\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/emmanuel/ecastillo/dev/delaware/02032024/project/vpvs/vps_stations.ipynb#W3sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m                  catalog_header_line\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mobject\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/emmanuel/ecastillo/dev/delaware/02032024/project/vpvs/vps_stations.ipynb#W3sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/emmanuel/ecastillo/dev/delaware/02032024/project/vpvs/vps_stations.ipynb#W3sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39m    Load earthquake picks and return an EQPicks object.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/emmanuel/ecastillo/dev/delaware/02032024/project/vpvs/vps_stations.ipynb#W3sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/emmanuel/ecastillo/dev/delaware/02032024/project/vpvs/vps_stations.ipynb#W3sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39m        EQPicks: An object containing earthquake picks data.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/emmanuel/ecastillo/dev/delaware/02032024/project/vpvs/vps_stations.ipynb#W3sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/emmanuel/ecastillo/dev/delaware/02032024/project/vpvs/vps_stations.ipynb#W3sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m EQPicks(root, author\u001b[39m=\u001b[39;49mauthor, xy_epsg\u001b[39m=\u001b[39;49mproj, \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/emmanuel/ecastillo/dev/delaware/02032024/project/vpvs/vps_stations.ipynb#W3sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m                    catalog_header_line\u001b[39m=\u001b[39;49mcatalog_header_line,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/emmanuel/ecastillo/dev/delaware/02032024/project/vpvs/vps_stations.ipynb#W3sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m                    catalog_path\u001b[39m=\u001b[39;49mcatalog_path, picks_path\u001b[39m=\u001b[39;49mpicks_path)\n",
      "File \u001b[0;32m~/ecastillo/dev/delaware/10102024/delaware/core/read.py:37\u001b[0m, in \u001b[0;36mEQPicks.__init__\u001b[0;34m(self, root, author, xy_epsg, catalog_header_line, catalog_path, picks_path)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcatalog_header_line \u001b[39m=\u001b[39m catalog_header_line\n\u001b[1;32m     36\u001b[0m catalog_fmt \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39msplitext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcatalog_path)[\u001b[39m1\u001b[39m]\n\u001b[0;32m---> 37\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcatalog \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_catalog(catalog_fmt)\n",
      "File \u001b[0;32m~/ecastillo/dev/delaware/10102024/delaware/core/read.py:41\u001b[0m, in \u001b[0;36mEQPicks._get_catalog\u001b[0;34m(self, catalog_fmt)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_catalog\u001b[39m(\u001b[39mself\u001b[39m,catalog_fmt):\n\u001b[1;32m     40\u001b[0m     \u001b[39mif\u001b[39;00m catalog_fmt \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.csv\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 41\u001b[0m         catalog \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcatalog_path,parse_dates\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39morigin_time\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     42\u001b[0m                             header\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcatalog_header_line)\n\u001b[1;32m     43\u001b[0m         catalog \u001b[39m=\u001b[39m catalog\u001b[39m.\u001b[39mdrop_duplicates(subset\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mev_id\u001b[39m\u001b[39m\"\u001b[39m],ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     45\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mmagnitude\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m catalog\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mto_list():\n",
      "File \u001b[0;32m~/anaconda3/envs/seismonitor/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/envs/seismonitor/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/envs/seismonitor/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/anaconda3/envs/seismonitor/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1898\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1895\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1897\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1898\u001b[0m     \u001b[39mreturn\u001b[39;00m mapping[engine](f, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions)\n\u001b[1;32m   1899\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   1900\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/seismonitor/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:161\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_usecols_names(\n\u001b[1;32m    156\u001b[0m             usecols,\n\u001b[1;32m    157\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnames,  \u001b[39m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m    158\u001b[0m         )\n\u001b[1;32m    160\u001b[0m \u001b[39m# error: Cannot determine type of 'names'\u001b[39;00m\n\u001b[0;32m--> 161\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_parse_dates_presence(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnames)  \u001b[39m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_noconvert_columns()\n\u001b[1;32m    164\u001b[0m \u001b[39m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/seismonitor/lib/python3.10/site-packages/pandas/io/parsers/base_parser.py:243\u001b[0m, in \u001b[0;36mParserBase._validate_parse_dates_presence\u001b[0;34m(self, columns)\u001b[0m\n\u001b[1;32m    233\u001b[0m missing_cols \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\n\u001b[1;32m    234\u001b[0m     \u001b[39msorted\u001b[39m(\n\u001b[1;32m    235\u001b[0m         {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    240\u001b[0m     )\n\u001b[1;32m    241\u001b[0m )\n\u001b[1;32m    242\u001b[0m \u001b[39mif\u001b[39;00m missing_cols:\n\u001b[0;32m--> 243\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    244\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMissing column provided to \u001b[39m\u001b[39m'\u001b[39m\u001b[39mparse_dates\u001b[39m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mmissing_cols\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    245\u001b[0m     )\n\u001b[1;32m    246\u001b[0m \u001b[39m# Convert positions to actual column names\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[39mreturn\u001b[39;00m [\n\u001b[1;32m    248\u001b[0m     col \u001b[39mif\u001b[39;00m (\u001b[39misinstance\u001b[39m(col, \u001b[39mstr\u001b[39m) \u001b[39mor\u001b[39;00m col \u001b[39min\u001b[39;00m columns) \u001b[39melse\u001b[39;00m columns[col]\n\u001b[1;32m    249\u001b[0m     \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m cols_needed\n\u001b[1;32m    250\u001b[0m ]\n",
      "\u001b[0;31mValueError\u001b[0m: Missing column provided to 'parse_dates': 'origin_time'"
     ]
    }
   ],
   "source": [
    "root = \"/home/emmanuel/ecastillo/dev/delaware/10102024/data/eq/aoi/growclust\"\n",
    "catalog_path = \"/home/emmanuel/ecastillo/dev/delaware/10102024/data/eq/aoi/growclust/origin.csv\"\n",
    "picks_path = \"/home/emmanuel/ecastillo/dev/delaware/10102024/data/eq/aoi/growclust/picks.db\"\n",
    "author = \"growclust\"\n",
    "proj = \"EPSG:3857\"\n",
    "stations_path = \"/home/emmanuel/ecastillo/dev/delaware/10102024/data_git/stations/standard_stations.csv\"\n",
    "\n",
    "r = 1 #in km\n",
    "# bins = np.arange(1, 3.02, 0.1)\n",
    "# station_list = [\"PB04\",\"PB16\"]\n",
    "\n",
    "custom_palette = {\"PB35\": \"#26fafa\", \n",
    "                  \"PB36\": \"#2dfa26\", \n",
    "                  \"PB28\": \"#ad16db\", \n",
    "                  \"PB37\": \"#1a3be3\", \n",
    "                  \"WB03\": \"#ffffff\", \n",
    "                  \"SA02\": \"#f1840f\", \n",
    "                  \"PB24\": \"#0ea024\", \n",
    "                  }\n",
    "station_list = list(custom_palette.keys())\n",
    "\n",
    "for station_name in station_list:\n",
    "    print(station_name)\n",
    "\n",
    "    stations = load_stations(stations_path, proj)\n",
    "    single_station = get_single_station(stations, station_name)\n",
    "\n",
    "    # Load EQPicks\n",
    "    eq_picks = load_eqpicks(root, author, proj, catalog_path, picks_path)\n",
    "\n",
    "    # Process catalog and picks\n",
    "    catalog, picks = process_catalog_and_picks(eq_picks, single_station,\n",
    "                                               stations=stations,\n",
    "                                               r=r)\n",
    "\n",
    "    # Preprocess picks\n",
    "    picks_data = preprocess_picks(picks, catalog)\n",
    "\n",
    "    # Calculate v_ij\n",
    "    results_df = calculate_vij(picks_data)\n",
    "    \n",
    "    path = os.path.join(\"/home/emmanuel/ecastillo/dev/delaware/02032024/project/vpvs/stations\",f\"{station_name}_{r}.csv\")\n",
    "    results_df.to_csv(path,index=False)\n",
    "    # Q1 = results_df['v_ij'].quantile(0.10)\n",
    "    # Q3 = results_df['v_ij'].quantile(0.90)\n",
    "    # iqr_results_df = results_df[(results_df['v_ij'] >= Q1) & (results_df['v_ij'] <= Q3)]\n",
    "    # print(iqr_results_df.describe())\n",
    "    # plot_vij_histogram(iqr_results_df,station_name,bins=bins,output=output_fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seismonitor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
